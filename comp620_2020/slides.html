<!DOCTYPE html>
<html>
  <head>
    <title>The Impact of Instruction Address Translation Overhead</title>
    <meta charset="utf-8">
    <style type="text/css">
      /* @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz); */
      /* @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic); */
      /* @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic); */

      /* body { font-family: 'Droid Serif'; } */
      body { font-family: 'Arial'; }
      h1, h2, h3 {
        /* font-family: 'Yanone Kaffeesatz'; */
        font-family: 'Arial';
        font-weight: normal;
      }
      .remark-slide-content {
        font-size: 22pt;
        line-height: 1.25;
      }
      .remark-slide-content h1 {
        font-size: 32pt;
      }
      .remark-slide-number {
        font-size: 18pt;
      }
      .title-institution { font-size: 18pt; }
      .title-email {
        font-size: 18pt;
        font-style: italic;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle

# On the Impact of Instruction Address Translation Overhead

**Yufeng Zhou**¹, Xiaowan Dong², Alan L. Cox¹, Sandhya Dwarkadas²

<div class="title-institution">¹Department of Computer Science, Rice University</div>

<div class="title-email">{yufengz, alc}@rice.edu</div>

<div class="title-institution">²Department of Computer Science, University of Rochester</div>

<div class="title-email">{xdong, sandhya}@cs.rochester.edu</div>

.bottom[![logos](./logos.svg)]

???
I'm very excited to be here today to talk about the impact of instruction address translation overhead. This is joint work done by folks from Rice University and the University of Rochester.

---

# Instruction Address Translation

![Instruction address translation](./addr_trans_fast_slow_0.svg)

- Significant instruction address translation overhead.
    - PostgreSQL database on a recent Intel Xeon processor: instruction address translation in progress during **14.9%** of execution cycles.
    - Intel documentation: worth investigating if &gt;**5%**.
    - Overhead exacerbated by two trends.
        1. Applications: bigger and more complex.
        2. The level of parallelism: constantly increasing.

???
So what is instruction address translation. In a virtual memory system, when the processor needs to fetch an instruction, it starts with a virtual address. Conceptually, the processor needs to translate that virtual address into a physical address before it can fetch the instruction from physical memory. **We call this instruction address translation.**

Now overhead caused by IAT can be pretty significant. For example, ...

In comparison, Intel suggests that if instruction address translation is happening during more than 5% of execution cycles, then it's a potential bottleneck that is worth investigating. So **clearly** it is a problem worth looking into.

Now people have looked at this problem before, mostly at the compiler level, by laying out code smartly. In this work, we will look at the OS level, which has largely been ignored. I would like to note that the compile-time techniques and OS-level techniques are complementary, and so one could easily apply both types of techniques and enjoy the benefits of both worlds.

---

# Instruction Address Translation - **Benefits of Superpages**

![Instruction address translation](./addr_trans_fast_slow_1.svg)

???
So what does address translation on these Intel processors look like? Conceptually, there is a fast path and a slow path, and the processor tries the fast path first, and then the slow path if the fast path doesn't work out.

The fast path is

When there is a miss in the TLB, we try the slow path, which is a page walk, where you go through this **4-level tree structure**, and at the last level, you get a table of entries, and one the entries will contain the physical address that you need. This is slow.

These translation structures in the TLB and page tables, they actually cover a consecutive range of memory. The finest granularity we have is a 4K page. Not exactly a large size these days. If you go up one level, you get to a 2M superpage, which consists of 512 consecutive 4K pages.

When you use superpages, ...

Obviously superpages can speed up address translation. So we wanna use them.

---

# Instruction Address Translation - **Missed Opportunities**

- Linux: No transparent and automatic superpages on code from a regular file system. Ugh. <font color="#ff6666">&#10008;</font>
- **FreeBSD**: transparent and automatic superpages on code from any file system. <font color="blue">&#10004;</font>
    - A conservative superpage policy: Don't bring in extra base pages merely for the purpose of creating superpages. <font color="orange">&#8263;</font>

???
What is the current state of OS support for code superpages?

Unfortunately, Linux ...

Fortunately, FreeBSD ...

We are gonna be hacking in FreeBSD because it at least has built-in support for the creation of code superpages from regular file systems.

Now if we look at the superpage policy in FreeBSD, it is a rather conservative one.

---

# Instruction Address Translation - **Missed Opportunities**

- Example: PostgreSQL on latest FreeBSD.
    - No code superpage under current policy.
    - A *simple* change in policy &rarr; ~2/3 of the main executable mapped with superpages.
        - **8.5%** reduction in execution cycles!

???
As an example, we take a look at PostgreSQL, which is emblematic of the kind of problem here.

In the rest of this talk, we are going to show the kinds of problems in instruction address translation, and we are gonna show just how large of an impact the instruction address translation overhead makes.

---

# Outline

- Problem #1: Conservative code superpage policy

- Problem #2: The residual code region

- Takeaways

???
The way this talk is organized, we are gonna basically go over the problems one after another.

It's ok if the problems don't make sense at this moment, I'll explain them.

---

class: center, middle

# Problem #1: A superpage policy that is too conservative for code.

???
With that, we are gonna jump right into problem #1, which we already touched on in the intro. But now we are gonna take a closer look.

<!-- &#45;&#45;&#45; -->
<!--  -->
<!-- # PostgreSQL Main Executable (5.953 MB) Page Access Map &#45; First 2MB Region -->
<!--  -->
<!-- ![postgres ktrace](./postgres_ktrace_2m_0.svg) -->
<!--  -->
<!-- &#45; 16 x 32 = 512 4KB pages = 2MB -->
<!--  -->
<!-- ??? -->
<!-- This figure is very important, and it's gonna show up multiple times in this talk. Essentially what going on here is that each little square here represents -->

---

# PostgreSQL Main Executable (5.953 MB) Page Access Map - First 2MB Region

![postgres ktrace](./postgres_ktrace_2m_1.svg)

- 16 x 32 = 512 4KB pages = 2MB
- 16 **consecutive** 4K pages per column.

???
Okay, there's a lot to unpack here. This figure is super important, and it's gonna show up repeatedly in this talk. So I'm spend some time walk you through this figure.

This figure shows how much of the first 2M superpage-sized region of the postgres main executable is accessed at a 4K granularity because again that is the finest granularity as far as page mappings are concerned. Note that the entire postgres main executable is roughly 6M, but we are only looking at the first 2M here for now. Obviously we will look at the rest in the next few slides.

Essentially what going on here is that each little square here represents a single 4K page. If it's black, it's accessed at some point, if it's white, it's not accessed at all. Simple. Now, the squares here are actually ordered.

Obviously there are 512 square boxes because there are precisely 512 4K pages in a 2M region. They are laid out here in a 16 by 32 matrix. So each column contains 16 consecutive 4K pages. This is important, and you are gonna see why in just two slides.

---

# PostgreSQL Main Executable (5.953 MB) - **No Superpage in First 4MB**

![postgres ktrace](./postgres_ktrace_4m.svg)

- First 2MB region: 259/512 4KB pages accessed.
- Second 2MB region: 241/512 4KB pages accessed.
- Naturally, **no superpage** under the conservative policy.

???
First 2 superpage-sized regions.

Not surprising, right?

it seems like superpages would result in loading lots of extra data from disk. "But actually if we look at how I/O from disk works.."

---

# PostgreSQL Main Executable (5.953 MB) - First 4MB, **I/O Clustering**

![postgres ktrace](./postgres_ktrace_4m_red_bars_01.svg)

- **I/O clustering**: The page fault handler reads from the disk at a 64KB granularity.

???
Well, it's actually more nuanced than what we just described.

brings in a 64K-aligned chunk at a time.

---

# PostgreSQL Main Executable (5.953 MB) - No Superpage in First 4MB, **but Actually Close**

![postgres ktrace](./postgres_ktrace_4m_red_bars_1.svg)

???
With I/O clustering in the page fault handler, what is really happening is that a lot more pages than we previously thought are memory-resident. All of the blue stuff in this figure is memory-resident. So in the first region, only 3 ...

Important observation that the 2M regions are only a few 64KB away from being fully resident. In other words, really close to qualifying for superpages.

---

# PostgreSQL Main Executable (5.953 MB) - No Superpage in First 4MB, but Actually Close

![postgres ktrace](./postgres_ktrace_4m_red_bars_2.svg)

- **Problem #1**: A superpage policy that is too conservative for code.
- **Solution**: Bring in the non-resident 64KB clusters and create a superpage.
    - \# of resident 64KB clusters in a 2MB region &#8805; threshold &rarr; superpage.

???
So we really oughta be more aggressive in bringing in code pages.

Now, whenever we aggressively does something in the OS, there is a question of threshold.

---

# Relaxed Code Superpage Policy Evaluation

![Thresholds](./superpg_exec_aggressive_color.svg)
- 6 workloads, 4 thresholds (lower threshold is more aggressive)

???
We can see from this figure that for all of the applications, a threshold of 15 is sufficient. A lower threshold or in other words a more aggressive policy doesn't really make a difference beyond that point. We believe this observation is generally applicable because code exhibits locality in the sense that the compiler tries to place functions with caller-callee relationships next to each other in the binary executable, and so if a code region should generally be heavily accessed if it's accessed at all.

Really what we are saying here is that you should be more aggressive with code superpages.

---

<!-- # Instruction Address Translation's Impact on Data Address Translation -->
<!--  -->
<!-- ![TLB](./tlb_config_min.svg) -->
<!--  -->
<!-- &#45; The second&#45;level TLB (STLB): *shared* between code and data. -->
<!--     &#45; Similar TLB organization in earlier Intel microarchitectures (e.g. Haswell (2013)). -->
<!-- &#45; **Realization**: Improved instruction address translation performance &#38;rarr; Improved data address translation performance! -->
<!--  -->
<!-- ??? -->
<!-- Now, we wanna point out something rather interesting here. -->
<!--  -->
<!-- &#45;&#45;&#45; -->
<!--  -->
<!-- # Data Address Translation Performance Synergistically Improves -->
<!--  -->
<!-- ![Data page walk](./data_pgwalk_thld1.svg) -->
<!--  -->
<!-- &#45;&#45;&#45; -->

# Problem #1 Summary

![postgres ktrace](./postgres_ktrace_4m_red_bars_2.svg)

- Relaxed code superpage policy &rarr; faster execution.
<!-- &#45; Improved instruction address translation performance &#38;rarr; improved data address translation performance! -->

???
To summarize, ... and essentially what we are saying here is that code pages deserve a more aggressive policy. Code and data have different access patterns, they have separate cache structures in the processor, and they should have different superpage policies.

Now we've looked at the first 4M of the PostgreSQL main executable. If you remember from earlier, the size of the main executable if almost 6M, and you might be wondering what happens with the last almost 2M of the main executable. Well, that brings us to

---

class: center, middle

# Problem #2: The residual code region.

???
So what is it?

---

# PostgreSQL Main Executable - Last "Almost 2MB"

![postgres ktrace](./postgres_ktrace_last2m.svg)

???
The total size of the main executable is almost 6M, so almost three superpage-sized regions. We discussed the first two regions in problem #1, and what you are seeing here is essentially the third region that is almost 2M in size. More precisely, it is 12 4K pages short of being 2M, and the missing 4K pages are shown with red crosses here.

---

# Problem #2: The Residual Code Region

![postgres ktrace](./postgres_ktrace_last2m_min.svg)

- Code region rarely an integer multiple of 2MB.
- The residual code region: the &lt; 2MB leftover region.
    - &lt; 2MB &rarr; no superpage.
    - Potentially hundreds of 4KB pages.
        - Risk of spilling into the second-level TLB (STLB).
- <font color="#006633">Would be nice if we can use a superpage here.</font>

???
, potentially displacing 2MB page mappings for data

---

# Solution: Padding

- Pad out the residual code region so that it becomes a superpage.

![postgres ktrace](./postgres_ktrace_last2m_padding.svg)

???
Think of it this way. The OS zero-fills the last 4K page for a file if the size of the file is not an integer multiple of 4K. This is essentially the same thing happening at a larger magnitude.

- Ask the **linker** to extend the text section.
- Modify the **kernel** to automatically extend the executable segment and fill in the gap with no-ops.

<!-- &#45;&#45;&#45; -->
<!--  -->
<!-- class: center, middle -->
<!--  -->
<!-- # Problem #3: Page table data duplication. -->
<!--  -->
<!-- &#45;&#45;&#45; -->
<!--  -->
<!-- # Problem #3: Page Table Data Duplication -->
<!--  -->
<!-- &#45; Common library code referenced across different processes and applications: libc, libcrypto, libm, etc. -->
<!--  -->
<!-- ![PT sharing](./pt_sharing_0.svg) -->
<!--  -->
<!-- ??? -->
<!-- This page table data, just like any other data, it's gonna compete for cache lines. -->
<!--  -->
<!-- &#45;&#45;&#45; -->
<!--  -->
<!-- # Solution: Page Table Page (PTP) Sharing -->
<!--  -->
<!-- ![PT sharing](./pt_sharing_1.svg) -->
<!--  -->
<!-- ??? -->
<!-- That brings us to PTP sharing. -->
<!--  -->
<!-- &#45;&#45;&#45; -->
<!--  -->
<!-- class: center, middle -->
<!--  -->
<!-- # Padding and PTP Sharing Evaluation -->
<!--  -->
<!-- ??? -->
<!-- Naturally, it's gonna lead to faster execution. What we wanna show next is the kinds of side effects that these techniques have. -->
<!--  -->
<!-- &#45;&#45;&#45; -->
<!--  -->
<!-- # Lower Pressure on Caches -->
<!--  -->
<!-- ![LLC stalls](./llc_stalls.svg) -->
<!--  -->
<!-- ??? -->
<!-- &#45; PTP sharing: Page table data de&#45;duplication. -->
<!-- &#45; Padding: Hundreds of leaf&#45;level page table entries (PTEs) &#38;rarr; a single upper&#45;level PTE. -->
<!--  -->
<!-- &#45;&#45;&#45; -->
<!--  -->
<!-- # Lower OS Memory Management Overhead -->
<!--  -->
<!-- ![OS counters](./os_counters_0.svg) -->
<!--  -->
<!-- ??? -->
<!-- &#45; Faster process creation and teardown. -->
<!--     &#45; PTP sharing: Insert/detach entire PTPs. -->
<!--     &#45; Padding: Hundreds of leaf&#45;level PTEs &#38;rarr; a single upper&#45;level PTE. -->
<!--  -->
---

# The Impact of Instruction Address Translation

- With all the techniques, execution cycles reduced by **18%**.
    - Without techniques, instruction address translation in progress during **~8%** of execution cycles.
- Less contention in the STLB and caches.
- Code patches included in production releases of FreeBSD since mid-2018.

---

# Takeaways

- Instruction address translation overhead is non-trivial (and will get worse).
- Unique problems and solutions at the OS level.
  - Conservative code superpage policy: relax the policy.
  - The residual code region: padding.

???
- Overhead exacerbated by two trends.
1. Applications are getting bigger and more complex.
- The Clang compiler: 31MB (2012) &rarr; 56MB (2018).
- A recent version of Node.js: 20 shared libraries.

2. The level of parallelism is increasing.
- Multi-core and SMT.
- Multi-process applications (e.g. PostgreSQL) and multi-process workloads (e.g. parallel compilation with Clang).

- Many modern microarchitectures share the STLB between instruction and data translations.

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({
        ratio: '16:9',
        countIncrementalSlides: false,
      });
    </script>
  </body>
</html>
